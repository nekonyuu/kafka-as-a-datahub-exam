# Projet de fin de cours - Sujet n°1

Nous allons faire un éternel *nouvel* essai sur la détection de sentiments sur
les tweets.

## Éléments
### Source de données

La source de données sera une liste de tweets extraite en anglais de Twitter il y a quelques mois.

Le jeu de données est téléchargeable [ici](https://ams3.digitaloceanspaces.com/nekonyuu42/work/nyuulabs/courses/kafka-data-hub/tweets.csv.gz?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=DHKQC67GSU2ARRU2Y5EQ%2F20180702%2Fams3%2Fs3%2Faws4_request&X-Amz-Date=20180702T122646Z&X-Amz-Expires=604800&X-Amz-SignedHeaders=host&X-Amz-Signature=9d3639b701b88be4282719778e0b5a9b423e3f604c11737a349d15e185b0c991).

Voici le schéma de ce CSV:
  * Date du tweet en format human readable ;
  * Requête faite à twitter pour récupérer ce tweet ;
  * Nick de l'utilisateur qui a produit le tweet ;
  * Message.

Vous devrez faire arriver le contenu de ce fichier en streaming, c'est à dire ligne par ligne, pour simuler 
l'arrivée de données depuis Twitter et permettre le calcul. Pensez à réécrire la date du tweet pour les besoins
du projet :).

### Kafka

Vous pouvez spawn votre propre Kafka si vous avez 
Docker (for Windows / for Mac) !

Une fois Docker et docker-compose (https://docs.docker.com/compose/install/) installé, allez dans le dossier `platform/docker` 
de ce dépôt et faites un `docker-compose up -d`.

Kafka sera exposé sur `localhost:29092` et Zookeeper sur `localhost:32181`.

## Applications à implémenter dans le cadre du projet

Vous devrez faire usage d'une techno de streaming dans ce projet, à choisir dans la dernière partie :).

Chacun de ces traitements devra être fait dans une application séparée 
(architecture de type microservices).

### Part 1 - Chargement des données

Dans un premier temps, il va être nécessaire de lire ces données et de les 
écrire dans un topic Kafka nommé `raw_tweets`. Vous pourrez faire cela de la
manière dont vous le souhaitez. Ces données devront être écrites ligne par ligne, par date
croissante, ce qui vous facilitera la vie ensuite.

### Part 2 - Extraction de sentiment

Une fois écrits dans ce topic, vous devrez faire de l'extraction de sentiment 
sur ces tweets, avec le framework Stanford CoreNLP (https://stanfordnlp.github.io/CoreNLP/).

L'API en question est https://stanfordnlp.github.io/CoreNLP/sentiment.html, à vous de voir
comment l'utiliser dans des transformations autour d'un KStream.

Cette API vous permettra d'extraire des tweets leur sentiment général, 
que vous écrirez sous format JSON dans un nouveau topic nommé `analyzed_tweets`.

### Part 3 - Metrics

Vous devrez ensuite faire des aggrégations sur les sentiments par:
  * user avec distribution de sentiment positif/neutre/négatif
  * par jour avec distribution de sentiment positif/neutre/négatif
  * par mois avec distribution de sentiment positif/neutre/négatif
  * par année avec distribution de sentiment positif/neutre/négatif
  * date, user avec distribution de sentiment positif/neutre/négatif.
    * Exemple: sur l'année N, par utilisateur, je veux la distribution de sentiments positifs/négatifs/neutres

Enfin, dans ces tweets, certains possèdent des hashtags. Vous devez 
extraire ces hashtags et extraire les hashtags les plus populaires 
par jour et par mois.

Chacune de ces aggrégations devra aller dans un topic, avec le nommage de votre choix.

### Part 4 - Dataviz

Enfin, développez une application simple exposant ces métriques via une API REST.

Tips How-To: https://blog.codecentric.de/en/2017/03/interactive-queries-in-apache-kafka-streams/ 

En bonus, vous pouvez y ajouter une application front affichant des graphes de
ces aggrégations, en récupérant les infos dans l'API.

Vous ne devez pas utiliser de base de données, les frameworks de streaming 
fournissent de quoi faire tout cela sans base :).

## Technos possibles (non limité)

  * Natural Language Processing 
    * Stanford CoreNLP: https://stanfordnlp.github.io/CoreNLP/
  * Streams
    * Spark Streaming: https://spark.apache.org/streaming/
    * Kafka Streams: https://kafka.apache.org/documentation/streams/
    * Akka Streams: https://doc.akka.io/docs/akka/2.5/stream/index.html
  * REST APIs
    * Play: https://www.playframework.com/
    * Akka-HTTP: https://doc.akka.io/docs/akka-http/current/
    * Spring Boot: https://spring.io/guides/gs/rest-service/
  * Viz
    * D3.js: https://d3js.org/
    * Highcharts: https://www.highcharts.com/

